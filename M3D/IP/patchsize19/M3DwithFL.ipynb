{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Project Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import truediv\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import scipy.io as sio\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import spectral\n",
    "import torch\n",
    "import math\n",
    "import wget\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Proposed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeEtAl(nn.Module):\n",
    "    \"\"\"\n",
    "    MULTI-SCALE 3D DEEP CONVOLUTIONAL NEURAL NETWORK FOR HYPERSPECTRAL\n",
    "    IMAGE CLASSIFICATION\n",
    "    Mingyi He, Bo Li, Huahui Chen\n",
    "    IEEE International Conference on Image Processing (ICIP) 2017\n",
    "    https://ieeexplore.ieee.org/document/8297014/\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(HeEtAl, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1, 16, (5, 3, 3), stride=(3, 1, 1))\n",
    "        self.conv2_1 = nn.Conv3d(16, 16, (1, 1, 1), padding=(0, 0, 0))\n",
    "        self.conv2_2 = nn.Conv3d(16, 16, (3, 1, 1), padding=(1, 0, 0))\n",
    "        self.conv2_3 = nn.Conv3d(16, 16, (5, 1, 1), padding=(2, 0, 0))\n",
    "        self.conv2_4 = nn.Conv3d(16, 16, (11, 1, 1), padding=(5, 0, 0))\n",
    "        self.conv3_1 = nn.Conv3d(16, 16, (1, 1, 1), padding=(0, 0, 0))\n",
    "        self.conv3_2 = nn.Conv3d(16, 16, (3, 1, 1), padding=(1, 0, 0))\n",
    "        self.conv3_3 = nn.Conv3d(16, 16, (5, 1, 1), padding=(2, 0, 0))\n",
    "        self.conv3_4 = nn.Conv3d(16, 16, (11, 1, 1), padding=(5, 0, 0))\n",
    "        self.conv4 = nn.Conv3d(16, 16, (3, 2, 2))\n",
    "        self.pooling = nn.MaxPool2d((3, 2, 2), stride=(3, 2, 2))\n",
    "        self.dropout = nn.Dropout(p=0.6)\n",
    "        self.fc1 = nn.Linear(8192, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, class_num)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x2_1 = self.conv2_1(x)\n",
    "        x2_2 = self.conv2_2(x)\n",
    "        x2_3 = self.conv2_3(x)\n",
    "        x2_4 = self.conv2_4(x)\n",
    "        x = x2_1 + x2_2 + x2_3 + x2_4\n",
    "        x = F.relu(x)\n",
    "        x3_1 = self.conv3_1(x)\n",
    "        x3_2 = self.conv3_2(x)\n",
    "        x3_3 = self.conv3_3(x)\n",
    "        x3_4 = self.conv3_4(x)\n",
    "        x = x3_1 + x3_2 + x3_3 + x3_4\n",
    "        x = F.relu(x)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        out = F.relu(self.dropout(self.fc1(x)))\n",
    "        out = F.relu(self.dropout(self.fc2(out)))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Preprocessing Modules"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 PCA for Data Dimensional Reducing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对高光谱数据 X 应用 PCA 变换\n",
    "def applyPCA(X, numComponents):\n",
    "    newX = np.reshape(X, (-1, X.shape[2]))\n",
    "    pca = PCA(n_components=numComponents, whiten=True)\n",
    "    newX = pca.fit_transform(newX)\n",
    "    newX = np.reshape(newX, (X.shape[0], X.shape[1], numComponents))\n",
    "    return newX"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Forming Patches of hyperspectral images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对单个像素周围提取 patch 时，边缘像素就无法取了，因此，给这部分像素进行 padding 操作\n",
    "def padWithZeros(X, margin=2):\n",
    "    newX = np.zeros(\n",
    "        (X.shape[0] + 2 * margin, X.shape[1] + 2 * margin, X.shape[2]))\n",
    "    x_offset = margin\n",
    "    y_offset = margin\n",
    "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
    "    return newX\n",
    "\n",
    "def createImageCubes(X, y, windowSize=5, removeZeroLabels=True):\n",
    "    # 给 X 做 padding\n",
    "    margin = int((windowSize - 1) / 2)\n",
    "    zeroPaddedX = padWithZeros(X, margin=margin)\n",
    "    # 获得 y 中的标记样本数---10249\n",
    "    count = 0\n",
    "    for r in range(0, y.shape[0]):\n",
    "        for c in range(0, y.shape[1]):\n",
    "            if y[r, c] != 0:\n",
    "                count = count + 1\n",
    "\n",
    "    # split patches\n",
    "    patchesData = np.zeros([count, windowSize, windowSize, X.shape[2]])\n",
    "    patchesLabels = np.zeros(count)\n",
    "\n",
    "    count = 0\n",
    "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
    "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
    "            if y[r - margin, c - margin] != 0:\n",
    "                patch = zeroPaddedX[r - margin:r + margin + 1,\n",
    "                                    c - margin:c + margin + 1]\n",
    "                patchesData[count, :, :, :] = patch\n",
    "                patchesLabels[count] = y[r - margin, c - margin]\n",
    "                count = count + 1\n",
    "\n",
    "    return patchesData, patchesLabels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Splitting Dataset into trainSet & testingSet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitTrainTestSet(X, y, testRatio, randomState=345):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=testRatio, random_state=randomState, stratify=y)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(name):\n",
    "    data_path = \"D:\\VsCode WorkSpace\\Hybrid2D&3D\\Data\"\n",
    "    if name == 'IP':\n",
    "        data = sio.loadmat(\n",
    "            os.path.join(data_path, 'Indian-Pines\\Indian_pines_corrected.mat')\n",
    "        )['indian_pines_corrected']\n",
    "        labels = sio.loadmat(\n",
    "            os.path.join(\n",
    "                data_path,\n",
    "                'Indian-Pines\\Indian_pines_gt.mat'))['indian_pines_gt']\n",
    "    elif name == 'SA':\n",
    "        data = sio.loadmat(\n",
    "            os.path.join(data_path,\n",
    "                         'Salinas\\Salinas_corrected.mat'))['salinas_corrected']\n",
    "        labels = sio.loadmat(os.path.join(\n",
    "            data_path, 'Salinas\\Salinas_gt.mat'))['salinas_gt']\n",
    "    elif name == 'PU':\n",
    "        data = sio.loadmat(\n",
    "            os.path.join(data_path, 'Pavia-University\\PaviaU.mat'))['paviaU']\n",
    "        labels = sio.loadmat(\n",
    "            os.path.join(data_path,\n",
    "                         'Pavia-University\\PaviaU_gt.mat'))['paviaU_gt']\n",
    "    else:\n",
    "        print(\"NO DATASET\")\n",
    "        exit()\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" testing set \"\"\"\n",
    "class TestDS(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.len = Xtest.shape[0]\n",
    "        self.x_data = torch.FloatTensor(Xtest)\n",
    "        self.y_data = torch.LongTensor(ytest)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 根据索引返回数据和对应的标签\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        # 返回文件数据的数目\n",
    "        return self.len\n",
    "\n",
    "\"\"\" training set \"\"\"\n",
    "class TrainDS(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.len = Xtrain.shape[0]\n",
    "        self.x_data = torch.FloatTensor(Xtrain)\n",
    "        self.y_data = torch.LongTensor(ytrain)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 根据索引返回数据和对应的标签\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        # 返回文件数据的数目\n",
    "        return self.len"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(input_values, gamma):\n",
    "    \"\"\"Computes the focal loss\"\"\"\n",
    "    p = torch.exp(-input_values)\n",
    "    #loss = (1 - p) ** gamma * input_values\n",
    "    loss = (1 - p)**gamma * input_values * 10\n",
    "    return loss.mean()\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None, gamma=0.):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        assert gamma >= 0\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return focal_loss(\n",
    "            F.cross_entropy(input,\n",
    "                            target,\n",
    "                            reduction='none',\n",
    "                            weight=self.weight), self.gamma)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training Samples Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperspectral data shape:  (145, 145, 200)\n",
      "Label shape:  (145, 145)\n",
      "\n",
      "... ... PCA tranformation ... ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape after PCA:  (145, 145, 15)\n",
      "\n",
      "... ... create data cubes ... ...\n",
      "Data cube X shape:  (10249, 19, 19, 15)\n",
      "Data cube y shape:  (10249,)\n",
      "\n",
      "... ... create train & test data ... ...\n",
      "Xtrain shape:  (1537, 19, 19, 15)\n",
      "Xtest  shape:  (8712, 19, 19, 15)\n",
      "before transpose: Xtrain shape:  (1537, 19, 19, 15, 1)\n",
      "before transpose: Xtest  shape:  (8712, 19, 19, 15, 1)\n",
      "after transpose: Xtrain shape:  (1537, 1, 15, 19, 19)\n",
      "after transpose: Xtest  shape:  (8712, 1, 15, 19, 19)\n"
     ]
    }
   ],
   "source": [
    "name = \"IP\"\n",
    "if (name == \"IP\" or name == \"SA\"):\n",
    "    class_num = 16\n",
    "elif (name == \"PU\"):\n",
    "    class_num = 9\n",
    "X, y = loadData(name)\n",
    "# 用于测试样本的比例\n",
    "test_ratio = 0.85\n",
    "# 每个像素周围提取 patch 的尺寸\n",
    "patch_size = 19\n",
    "# 使用 PCA 降维，得到主成分的数量\n",
    "pca_components = 15\n",
    "\n",
    "print('Hyperspectral data shape: ', X.shape)  \n",
    "print('Label shape: ', y.shape)  \n",
    "\n",
    "print('\\n... ... PCA tranformation ... ...')\n",
    "X_pca = applyPCA(X, numComponents=pca_components)\n",
    "print('Data shape after PCA: ', X_pca.shape)  \n",
    "\n",
    "print('\\n... ... create data cubes ... ...')\n",
    "X_pca, y = createImageCubes(\n",
    "    X_pca, y, windowSize=patch_size) \n",
    "print('Data cube X shape: ', X_pca.shape)  \n",
    "print('Data cube y shape: ', y.shape)  \n",
    "\n",
    "print('\\n... ... create train & test data ... ...')\n",
    "Xtrain, Xtest, ytrain, ytest = splitTrainTestSet(X_pca, y, test_ratio)\n",
    "print('Xtrain shape: ', Xtrain.shape)  \n",
    "print('Xtest  shape: ', Xtest.shape)  \n",
    "\n",
    "# 改变 Xtrain, Ytrain 的形状，以符合 keras 的要求\n",
    "Xtrain = Xtrain.reshape(-1, patch_size, patch_size, pca_components, 1)\n",
    "Xtest = Xtest.reshape(-1, patch_size, patch_size, pca_components, 1)\n",
    "print('before transpose: Xtrain shape: ', Xtrain.shape)  \n",
    "print('before transpose: Xtest  shape: ', Xtest.shape)  \n",
    "\n",
    "# 为了适应 pytorch 结构，数据要做 transpose\n",
    "Xtrain = Xtrain.transpose(0, 4, 3, 1, 2)\n",
    "Xtest = Xtest.transpose(0, 4, 3, 1, 2)\n",
    "print('after transpose: Xtrain shape: ', Xtrain.shape)  \n",
    "print('after transpose: Xtest  shape: ', Xtest.shape)  \n",
    "\"\"\"在此之前都是对数据的预处理\"\"\"\n",
    "###########数据加载loader############\n",
    "# 创建 trainloader 和 testloader\n",
    "trainset = TrainDS()\n",
    "testset = TestDS()\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=trainset,\n",
    "    batch_size=53,  # 128,53\n",
    "    shuffle=True,\n",
    "    num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=testset,\n",
    "    batch_size=53,  # 128,53\n",
    "    shuffle=False,\n",
    "    num_workers=0)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "one = torch.ones(53, dtype=torch.long).to(device)\n",
    "if test_ratio == 0.85:\n",
    "    two = torch.ones(9, dtype=torch.long).to(device)\n",
    "elif test_ratio == 0.90:\n",
    "    two = torch.ones(17, dtype=torch.long).to(device)\n",
    "elif test_ratio == 0.95:\n",
    "    two = torch.ones(35, dtype=torch.long).to(device)\n",
    "\n",
    "# 网络放到GPU上,一些metric的设定\n",
    "net = HeEtAl().to(device)\n",
    "criterion = FocalLoss().to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1]   [loss avg: 684.7202]   [current loss: 18.8690]\n",
      "[Epoch: 2]   [loss avg: 606.2855]   [current loss: 17.7467]\n",
      "[Epoch: 3]   [loss avg: 547.6130]   [current loss: 13.5788]\n",
      "[Epoch: 4]   [loss avg: 498.9432]   [current loss: 11.0643]\n",
      "[Epoch: 5]   [loss avg: 453.9554]   [current loss: 7.9030]\n",
      "[Epoch: 6]   [loss avg: 411.2468]   [current loss: 4.3446]\n",
      "[Epoch: 7]   [loss avg: 375.5805]   [current loss: 7.8299]\n",
      "[Epoch: 8]   [loss avg: 345.0539]   [current loss: 5.0040]\n",
      "[Epoch: 9]   [loss avg: 319.1319]   [current loss: 3.6757]\n",
      "[Epoch: 10]   [loss avg: 296.5373]   [current loss: 4.6727]\n",
      "[Epoch: 11]   [loss avg: 277.0706]   [current loss: 2.4927]\n",
      "[Epoch: 12]   [loss avg: 258.8025]   [current loss: 2.4235]\n",
      "[Epoch: 13]   [loss avg: 243.5795]   [current loss: 1.2852]\n",
      "[Epoch: 14]   [loss avg: 230.0868]   [current loss: 1.1757]\n",
      "[Epoch: 15]   [loss avg: 218.6360]   [current loss: 1.8138]\n",
      "[Epoch: 16]   [loss avg: 207.8530]   [current loss: 1.1762]\n",
      "[Epoch: 17]   [loss avg: 197.7735]   [current loss: 0.2710]\n",
      "[Epoch: 18]   [loss avg: 188.6715]   [current loss: 0.4587]\n",
      "[Epoch: 19]   [loss avg: 180.5531]   [current loss: 0.5940]\n",
      "[Epoch: 20]   [loss avg: 172.7991]   [current loss: 0.8492]\n",
      "[Epoch: 21]   [loss avg: 165.9128]   [current loss: 0.3646]\n",
      "[Epoch: 22]   [loss avg: 159.6072]   [current loss: 0.5798]\n",
      "[Epoch: 23]   [loss avg: 154.3560]   [current loss: 1.0858]\n",
      "[Epoch: 24]   [loss avg: 150.2102]   [current loss: 1.6814]\n",
      "[Epoch: 25]   [loss avg: 145.3411]   [current loss: 0.9406]\n",
      "[Epoch: 26]   [loss avg: 140.6725]   [current loss: 1.4940]\n",
      "[Epoch: 27]   [loss avg: 136.4960]   [current loss: 1.0674]\n",
      "[Epoch: 28]   [loss avg: 132.6985]   [current loss: 0.7158]\n",
      "[Epoch: 29]   [loss avg: 129.1127]   [current loss: 1.1941]\n",
      "[Epoch: 30]   [loss avg: 125.6284]   [current loss: 0.6939]\n",
      "[Epoch: 31]   [loss avg: 122.3507]   [current loss: 1.9914]\n",
      "[Epoch: 32]   [loss avg: 119.2530]   [current loss: 0.6597]\n",
      "[Epoch: 33]   [loss avg: 116.2739]   [current loss: 0.2039]\n",
      "[Epoch: 34]   [loss avg: 113.7021]   [current loss: 0.8621]\n",
      "[Epoch: 35]   [loss avg: 110.9351]   [current loss: 0.5307]\n",
      "[Epoch: 36]   [loss avg: 108.1976]   [current loss: 0.7183]\n",
      "[Epoch: 37]   [loss avg: 105.6493]   [current loss: 0.0019]\n",
      "[Epoch: 38]   [loss avg: 103.2926]   [current loss: 0.0506]\n",
      "[Epoch: 39]   [loss avg: 101.0299]   [current loss: 0.0162]\n",
      "[Epoch: 40]   [loss avg: 98.9599]   [current loss: 0.8899]\n",
      "[Epoch: 41]   [loss avg: 97.1889]   [current loss: 0.6305]\n",
      "[Epoch: 42]   [loss avg: 95.3360]   [current loss: 2.1575]\n",
      "[Epoch: 43]   [loss avg: 93.4228]   [current loss: 1.3082]\n",
      "[Epoch: 44]   [loss avg: 91.6028]   [current loss: 0.3450]\n",
      "[Epoch: 45]   [loss avg: 89.9159]   [current loss: 0.3260]\n",
      "[Epoch: 46]   [loss avg: 88.2341]   [current loss: 0.7613]\n",
      "[Epoch: 47]   [loss avg: 86.6190]   [current loss: 0.0851]\n",
      "[Epoch: 48]   [loss avg: 85.1005]   [current loss: 0.3487]\n",
      "[Epoch: 49]   [loss avg: 83.6583]   [current loss: 0.2071]\n",
      "[Epoch: 50]   [loss avg: 82.4722]   [current loss: 0.6750]\n",
      "[Epoch: 51]   [loss avg: 81.2228]   [current loss: 0.0729]\n",
      "[Epoch: 52]   [loss avg: 79.9782]   [current loss: 0.7565]\n",
      "[Epoch: 53]   [loss avg: 78.6066]   [current loss: 0.1649]\n",
      "[Epoch: 54]   [loss avg: 77.4555]   [current loss: 0.0134]\n",
      "[Epoch: 55]   [loss avg: 76.2693]   [current loss: 0.0255]\n",
      "[Epoch: 56]   [loss avg: 75.0558]   [current loss: 0.2777]\n",
      "[Epoch: 57]   [loss avg: 73.9990]   [current loss: 0.8924]\n",
      "[Epoch: 58]   [loss avg: 72.9113]   [current loss: 0.4612]\n",
      "[Epoch: 59]   [loss avg: 71.9106]   [current loss: 0.3010]\n",
      "[Epoch: 60]   [loss avg: 70.9577]   [current loss: 0.1805]\n",
      "[Epoch: 61]   [loss avg: 70.0070]   [current loss: 0.1911]\n",
      "[Epoch: 62]   [loss avg: 69.0399]   [current loss: 0.0221]\n",
      "[Epoch: 63]   [loss avg: 68.1356]   [current loss: 0.2356]\n",
      "[Epoch: 64]   [loss avg: 67.2140]   [current loss: 0.1203]\n",
      "[Epoch: 65]   [loss avg: 66.2975]   [current loss: 0.0821]\n",
      "[Epoch: 66]   [loss avg: 65.4369]   [current loss: 0.0170]\n",
      "[Epoch: 67]   [loss avg: 64.6767]   [current loss: 1.1618]\n",
      "[Epoch: 68]   [loss avg: 63.8801]   [current loss: 0.0752]\n",
      "[Epoch: 69]   [loss avg: 63.1071]   [current loss: 0.2488]\n",
      "[Epoch: 70]   [loss avg: 62.3234]   [current loss: 0.0436]\n",
      "[Epoch: 71]   [loss avg: 61.6442]   [current loss: 0.2709]\n",
      "[Epoch: 72]   [loss avg: 60.8811]   [current loss: 0.2204]\n",
      "[Epoch: 73]   [loss avg: 60.1394]   [current loss: 0.0022]\n",
      "[Epoch: 74]   [loss avg: 59.4862]   [current loss: 0.1212]\n",
      "[Epoch: 75]   [loss avg: 58.7871]   [current loss: 0.0008]\n",
      "[Epoch: 76]   [loss avg: 58.0807]   [current loss: 0.1226]\n",
      "[Epoch: 77]   [loss avg: 57.4131]   [current loss: 0.4327]\n",
      "[Epoch: 78]   [loss avg: 56.7653]   [current loss: 0.4978]\n",
      "[Epoch: 79]   [loss avg: 56.1309]   [current loss: 0.7265]\n",
      "[Epoch: 80]   [loss avg: 55.5680]   [current loss: 0.0167]\n",
      "[Epoch: 81]   [loss avg: 55.0254]   [current loss: 0.3466]\n",
      "[Epoch: 82]   [loss avg: 54.4733]   [current loss: 0.0003]\n",
      "[Epoch: 83]   [loss avg: 54.0970]   [current loss: 0.0485]\n",
      "[Epoch: 84]   [loss avg: 53.5796]   [current loss: 0.8124]\n",
      "[Epoch: 85]   [loss avg: 53.1569]   [current loss: 0.0500]\n",
      "[Epoch: 86]   [loss avg: 52.7230]   [current loss: 0.0800]\n",
      "[Epoch: 87]   [loss avg: 52.2929]   [current loss: 0.0258]\n",
      "[Epoch: 88]   [loss avg: 51.7986]   [current loss: 0.0928]\n",
      "[Epoch: 89]   [loss avg: 51.3293]   [current loss: 0.4229]\n",
      "[Epoch: 90]   [loss avg: 50.8958]   [current loss: 0.0124]\n",
      "[Epoch: 91]   [loss avg: 50.4367]   [current loss: 0.1919]\n",
      "[Epoch: 92]   [loss avg: 49.9819]   [current loss: 0.2707]\n",
      "[Epoch: 93]   [loss avg: 49.5330]   [current loss: 0.4754]\n",
      "[Epoch: 94]   [loss avg: 49.1396]   [current loss: 0.2293]\n",
      "[Epoch: 95]   [loss avg: 48.8481]   [current loss: 0.7165]\n",
      "[Epoch: 96]   [loss avg: 48.4458]   [current loss: 0.1170]\n",
      "[Epoch: 97]   [loss avg: 48.0505]   [current loss: 0.0790]\n",
      "[Epoch: 98]   [loss avg: 47.6438]   [current loss: 0.1724]\n",
      "[Epoch: 99]   [loss avg: 47.2724]   [current loss: 0.0302]\n",
      "[Epoch: 100]   [loss avg: 46.8922]   [current loss: 0.1461]\n",
      "[Epoch: 101]   [loss avg: 46.5129]   [current loss: 0.0552]\n",
      "[Epoch: 102]   [loss avg: 46.1131]   [current loss: 0.4495]\n",
      "[Epoch: 103]   [loss avg: 45.7027]   [current loss: 0.0973]\n",
      "[Epoch: 104]   [loss avg: 45.3218]   [current loss: 0.2135]\n",
      "[Epoch: 105]   [loss avg: 44.9557]   [current loss: 0.0082]\n",
      "[Epoch: 106]   [loss avg: 44.6189]   [current loss: 0.3884]\n",
      "[Epoch: 107]   [loss avg: 44.3104]   [current loss: 0.0797]\n",
      "[Epoch: 108]   [loss avg: 44.0034]   [current loss: 0.4071]\n",
      "[Epoch: 109]   [loss avg: 43.6937]   [current loss: 0.2782]\n",
      "[Epoch: 110]   [loss avg: 43.3899]   [current loss: 0.8183]\n",
      "[Epoch: 111]   [loss avg: 43.1506]   [current loss: 0.7875]\n",
      "[Epoch: 112]   [loss avg: 42.8716]   [current loss: 0.4338]\n",
      "[Epoch: 113]   [loss avg: 42.5918]   [current loss: 0.0602]\n",
      "[Epoch: 114]   [loss avg: 42.2457]   [current loss: 0.3727]\n",
      "[Epoch: 115]   [loss avg: 41.9147]   [current loss: 0.0959]\n",
      "[Epoch: 116]   [loss avg: 41.5792]   [current loss: 0.0005]\n",
      "[Epoch: 117]   [loss avg: 41.3159]   [current loss: 0.1173]\n",
      "[Epoch: 118]   [loss avg: 41.0241]   [current loss: 0.1614]\n",
      "[Epoch: 119]   [loss avg: 40.7142]   [current loss: 0.0397]\n",
      "[Epoch: 120]   [loss avg: 40.4186]   [current loss: 0.0017]\n",
      "[Epoch: 121]   [loss avg: 40.1786]   [current loss: 1.5624]\n",
      "[Epoch: 122]   [loss avg: 39.8960]   [current loss: 0.0023]\n",
      "[Epoch: 123]   [loss avg: 39.6112]   [current loss: 0.0231]\n",
      "[Epoch: 124]   [loss avg: 39.3578]   [current loss: 0.0871]\n",
      "[Epoch: 125]   [loss avg: 39.1610]   [current loss: 1.6438]\n",
      "[Epoch: 126]   [loss avg: 38.9150]   [current loss: 0.0476]\n",
      "[Epoch: 127]   [loss avg: 38.6540]   [current loss: 0.0024]\n",
      "[Epoch: 128]   [loss avg: 38.5409]   [current loss: 2.6989]\n",
      "[Epoch: 129]   [loss avg: 38.3981]   [current loss: 0.5288]\n",
      "[Epoch: 130]   [loss avg: 38.1701]   [current loss: 0.0102]\n",
      "[Epoch: 131]   [loss avg: 37.9727]   [current loss: 0.0984]\n",
      "[Epoch: 132]   [loss avg: 37.8196]   [current loss: 0.0394]\n",
      "[Epoch: 133]   [loss avg: 37.6342]   [current loss: 0.3368]\n",
      "[Epoch: 134]   [loss avg: 37.5181]   [current loss: 0.1617]\n",
      "[Epoch: 135]   [loss avg: 37.3211]   [current loss: 0.8463]\n",
      "[Epoch: 136]   [loss avg: 37.0908]   [current loss: 0.2868]\n",
      "[Epoch: 137]   [loss avg: 36.8516]   [current loss: 0.0208]\n",
      "[Epoch: 138]   [loss avg: 36.6778]   [current loss: 0.3660]\n",
      "[Epoch: 139]   [loss avg: 36.4726]   [current loss: 0.3231]\n",
      "[Epoch: 140]   [loss avg: 36.2815]   [current loss: 0.2385]\n",
      "[Epoch: 141]   [loss avg: 36.0552]   [current loss: 0.0515]\n",
      "[Epoch: 142]   [loss avg: 35.8499]   [current loss: 0.0183]\n",
      "[Epoch: 143]   [loss avg: 35.6217]   [current loss: 0.1118]\n",
      "[Epoch: 144]   [loss avg: 35.4021]   [current loss: 0.0707]\n",
      "[Epoch: 145]   [loss avg: 35.1950]   [current loss: 0.2290]\n",
      "[Epoch: 146]   [loss avg: 34.9817]   [current loss: 0.0021]\n",
      "[Epoch: 147]   [loss avg: 34.7686]   [current loss: 0.5675]\n",
      "[Epoch: 148]   [loss avg: 34.5543]   [current loss: 0.3238]\n",
      "[Epoch: 149]   [loss avg: 34.3473]   [current loss: 0.6287]\n",
      "[Epoch: 150]   [loss avg: 34.1837]   [current loss: 0.0596]\n"
     ]
    }
   ],
   "source": [
    "# 训练开始时间\n",
    "start_time = time.time()\n",
    "\n",
    "net.train()\n",
    "total_loss = 0\n",
    "# proc_bar = tqdm(range(150))\n",
    "for epoch in range(150):\n",
    "    # proc_bar.set_description(f\"正处于第{epoch}回合：\")\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        try:\n",
    "            labels = labels - one\n",
    "        except:\n",
    "            labels = labels - two\n",
    "        #print(labels)\n",
    "        # 优化器梯度归零\n",
    "        optimizer.zero_grad()\n",
    "        # 正向传播 +　反向传播 + 优化\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print('[Epoch: %d]   [loss avg: %.4f]   [current loss: %.4f]' %\n",
    "          (epoch + 1, total_loss / (epoch + 1), loss.item()))\n",
    "\n",
    "# proc_bar.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time cost:2.9721561392148335 min\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "print(f\"time cost:{(end_time-start_time)/60} min\")\n",
    "print('Finished Training')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Saving & Outputing the model params of proposed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1        [-1, 16, 4, 17, 17]             736\n",
      "            Conv3d-2        [-1, 16, 4, 17, 17]             272\n",
      "            Conv3d-3        [-1, 16, 4, 17, 17]             784\n",
      "            Conv3d-4        [-1, 16, 4, 17, 17]           1,296\n",
      "            Conv3d-5        [-1, 16, 4, 17, 17]           2,832\n",
      "            Conv3d-6        [-1, 16, 4, 17, 17]             272\n",
      "            Conv3d-7        [-1, 16, 4, 17, 17]             784\n",
      "            Conv3d-8        [-1, 16, 4, 17, 17]           1,296\n",
      "            Conv3d-9        [-1, 16, 4, 17, 17]           2,832\n",
      "           Conv3d-10        [-1, 16, 2, 16, 16]           3,088\n",
      "           Linear-11                  [-1, 256]       2,097,408\n",
      "          Dropout-12                  [-1, 256]               0\n",
      "           Linear-13                  [-1, 128]          32,896\n",
      "          Dropout-14                  [-1, 128]               0\n",
      "           Linear-15                   [-1, 16]           2,064\n",
      "================================================================\n",
      "Total params: 2,146,560\n",
      "Trainable params: 2,146,560\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 1.34\n",
      "Params size (MB): 8.19\n",
      "Estimated Total Size (MB): 9.55\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 指定模型保存的地址\n",
    "path = r'D:\\VsCode WorkSpace\\FEHN-FL\\Assets\\M3D\\IP-Patch19\\model.pth'\n",
    "torch.save(net, path)\n",
    "# 输出模型参数\n",
    "summary(net, (1, 15, 19, 19))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Evaluating the proposed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones(Xtest.shape[0])  ##9225是Xtest.shape[0]\n",
    "ytest = ytest - a\n",
    "\n",
    "count = 0\n",
    "# 模型测试\n",
    "net.eval()\n",
    "for inputs, _ in test_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    outputs = net(inputs)\n",
    "    outputs = np.argmax(outputs.detach().cpu().numpy(), axis=1)\n",
    "    if count == 0:\n",
    "        y_pred_test = outputs\n",
    "        count = 1\n",
    "    else:\n",
    "        y_pred_test = np.concatenate((y_pred_test, outputs))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Generating the report of evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 text report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000        39\n",
      "         1.0     0.9681    0.9489    0.9584      1214\n",
      "         2.0     0.9826    0.9589    0.9706       706\n",
      "         3.0     0.9327    0.9652    0.9487       201\n",
      "         4.0     0.9808    0.9927    0.9867       411\n",
      "         5.0     0.9873    0.9984    0.9928       621\n",
      "         6.0     1.0000    0.9583    0.9787        24\n",
      "         7.0     1.0000    1.0000    1.0000       406\n",
      "         8.0     0.8889    0.9412    0.9143        17\n",
      "         9.0     0.9797    0.9915    0.9856       826\n",
      "        10.0     0.9696    0.9938    0.9815      2087\n",
      "        11.0     0.9934    0.8948    0.9415       504\n",
      "        12.0     1.0000    0.9885    0.9942       174\n",
      "        13.0     0.9935    0.9991    0.9963      1075\n",
      "        14.0     0.9968    0.9604    0.9783       328\n",
      "        15.0     0.8144    1.0000    0.8977        79\n",
      "\n",
      "    accuracy                         0.9778      8712\n",
      "   macro avg     0.9680    0.9745    0.9703      8712\n",
      "weighted avg     0.9784    0.9778    0.9778      8712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 生成分类报告\n",
    "classification = classification_report(ytest, y_pred_test, digits=4)\n",
    "print(classification)\n",
    "\n",
    "\n",
    "def AA_andEachClassAccuracy(confusion_matrix):\n",
    "    counter = confusion_matrix.shape[0]\n",
    "    list_diag = np.diag(confusion_matrix)\n",
    "    list_raw_sum = np.sum(confusion_matrix, axis=1)\n",
    "    each_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
    "    average_acc = np.mean(each_acc)\n",
    "    return each_acc, average_acc\n",
    "\n",
    "\n",
    "def reports(test_loader, y_test, name):\n",
    "    count = 0\n",
    "    # 模型测试\n",
    "    for inputs, _ in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = net(inputs)\n",
    "        outputs = np.argmax(outputs.detach().cpu().numpy(), axis=1)\n",
    "        if count == 0:\n",
    "            y_pred = outputs\n",
    "            count = 1\n",
    "        else:\n",
    "            y_pred = np.concatenate((y_pred, outputs))\n",
    "\n",
    "    if name == 'IP':\n",
    "        target_names = [\n",
    "            'Alfalfa', 'Corn-notill', 'Corn-mintill', 'Corn', 'Grass-pasture',\n",
    "            'Grass-trees', 'Grass-pasture-mowed', 'Hay-windrowed', 'Oats',\n",
    "            'Soybean-notill', 'Soybean-mintill', 'Soybean-clean', 'Wheat',\n",
    "            'Woods', 'Buildings-Grass-Trees-Drives', 'Stone-Steel-Towers'\n",
    "        ]\n",
    "    elif name == 'SA':\n",
    "        target_names = [\n",
    "            'Brocoli_green_weeds_1', 'Brocoli_green_weeds_2', 'Fallow',\n",
    "            'Fallow_rough_plow', 'Fallow_smooth', 'Stubble', 'Celery',\n",
    "            'Grapes_untrained', 'Soil_vinyard_develop',\n",
    "            'Corn_senesced_green_weeds', 'Lettuce_romaine_4wk',\n",
    "            'Lettuce_romaine_5wk', 'Lettuce_romaine_6wk',\n",
    "            'Lettuce_romaine_7wk', 'Vinyard_untrained',\n",
    "            'Vinyard_vertical_trellis'\n",
    "        ]\n",
    "    elif name == 'PU':\n",
    "        target_names = [\n",
    "            'Asphalt', 'Meadows', 'Gravel', 'Trees', 'Painted metal sheets',\n",
    "            'Bare Soil', 'Bitumen', 'Self-Blocking Bricks', 'Shadows'\n",
    "        ]\n",
    "\n",
    "    classification = classification_report(y_test,\n",
    "                                           y_pred,\n",
    "                                           target_names=target_names)\n",
    "    oa = accuracy_score(y_test, y_pred)\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    each_acc, aa = AA_andEachClassAccuracy(confusion)\n",
    "    kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "    return classification, confusion, oa * 100, each_acc * 100, aa * 100, kappa * 100\n",
    "\n",
    "\n",
    "# 将结果写在文件里\n",
    "classification, confusion, oa, each_acc, aa, kappa = reports(\n",
    "    test_loader, ytest, name)\n",
    "classification = str(classification)\n",
    "confusion = str(confusion)\n",
    "file_name = r\"D:\\VsCode WorkSpace\\FEHN-FL\\Assets\\M3D\\IP-Patch19\\classification_report(0.85-loss).txt\"\n",
    "\n",
    "with open(file_name, 'w') as x_file:\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Kappa accuracy (%)'.format(kappa))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Overall accuracy (%)'.format(oa))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Average accuracy (%)'.format(aa))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} training time (min)'.format((end_time-start_time)/60))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{}'.format(classification))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{}'.format(confusion))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 images of prediction report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... ... row  0  handling ... ...\n",
      "... ... row  20  handling ... ...\n",
      "... ... row  40  handling ... ...\n",
      "... ... row  60  handling ... ...\n",
      "... ... row  80  handling ... ...\n",
      "... ... row  100  handling ... ...\n",
      "... ... row  120  handling ... ...\n",
      "... ... row  140  handling ... ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\torch\\lib\\site-packages\\spectral\\graphics\\spypylab.py:796: UserWarning: Failed to create RectangleSelector object. Interactive pixel class labeling will be unavailable.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 显示结果\n",
    "# load the original image\n",
    "\n",
    "my_color4IP = np.array([[255, 255, 255], [223, 214, 212], [191, 173, 169],\n",
    "                        [159, 132, 126], [128, 92, 84], [160, 133, 102],\n",
    "                        [192, 174, 119], [224, 215, 136], [253, 255, 153],\n",
    "                        [189, 242, 140], [125, 229, 127], [61, 216, 114],\n",
    "                        [0, 202, 106], [0, 170, 202], [10, 134, 236],\n",
    "                        [31, 91, 193], [51, 51, 153]])\n",
    "\n",
    "# my_color4IP_predict = np.array([[51, 204, 255], [223, 214, 212], [191, 173, 169],\n",
    "#                         [159, 132, 126], [128, 92, 84], [160, 133, 102],\n",
    "#                         [192, 174, 119], [224, 215, 136], [253, 255, 153],\n",
    "#                         [189, 242, 140], [125, 229, 127], [61, 216, 114],\n",
    "#                         [0, 202, 106], [0, 170, 202], [10, 134, 236],\n",
    "#                         [31, 91, 193], [51, 51, 153]])\n",
    "\n",
    "my_color4IP_predict = my_color4IP\n",
    "\n",
    "\n",
    "X, y = loadData(name)\n",
    "\n",
    "height = y.shape[0]\n",
    "width = y.shape[1]\n",
    "\n",
    "X = applyPCA(X, numComponents=pca_components)\n",
    "X = padWithZeros(X, patch_size // 2)\n",
    "\n",
    "# 逐像素预测类别\n",
    "outputs = np.zeros((height, width))\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "        if int(y[i, j]) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            image_patch = X[i:i + patch_size, j:j + patch_size, :]\n",
    "            image_patch = image_patch.reshape(1, image_patch.shape[0],\n",
    "                                              image_patch.shape[1],\n",
    "                                              image_patch.shape[2], 1)\n",
    "            X_test_image = torch.FloatTensor(\n",
    "                image_patch.transpose(0, 4, 3, 1, 2)).to(device)\n",
    "            prediction = net(X_test_image)\n",
    "            prediction = np.argmax(prediction.detach().cpu().numpy(), axis=1)\n",
    "            outputs[i][j] = prediction + 1\n",
    "    if i % 20 == 0:\n",
    "        print('... ... row ', i, ' handling ... ...')\n",
    "\n",
    "# oringal_image = spectral.imshow(classes=y, figsize=(5, 5))\n",
    "predict_image = spectral.imshow(classes=outputs.astype(int), figsize=(5, 5))\n",
    "# spectral.save_rgb(\"D:\\VsCode WorkSpace\\FEHN-FL\\Pics\\IP-15%-FEHN\\(PU-3-3-0.85)FE-NET-原始.eps\",\n",
    "#                   y.astype(int),\n",
    "#                   colors=my_color4IP)\n",
    "spectral.save_rgb(r\"D:\\VsCode WorkSpace\\FEHN-FL\\Pics\\IP-15%-FEHN\\m3d.eps\",\n",
    "                  outputs.astype(int),\n",
    "                  colors=my_color4IP_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
